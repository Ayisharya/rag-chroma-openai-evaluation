# -*- coding: utf-8 -*-
"""rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VJrGNFlBPkURQntYAGy2puSe7FS7NM8M
"""



!pip install chromadb pymupdf langchain openai langchain-openai

!pip install langchain-text-splitters

!pip install -q langchain langchain-openai langchain-community chromadb

!pip install ragas datasets

import fitz

def extract_pdf_text(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    doc.close()
    return text

pdf_path = "/content/ecb.wp2409~79137cac1e.en.pdf"
raw_text = extract_pdf_text(pdf_path)
len(raw_text)

from langchain_text_splitters import RecursiveCharacterTextSplitter
splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=150
)

chunks = splitter.split_text(raw_text)
len(chunks)

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma


embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key="your-openai-key")

vectordb = Chroma.from_texts(
    texts=chunks,
    embedding=embeddings,
    collection_name="pdf_rag"
)

retriever = vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 4})

from openai import OpenAI
client = OpenAI(api_key="your-openai-key")

def ask_question(query):
    # retrieve docs with the new API
    docs = retriever.invoke(query)

    # extract text from docs
    context = "\n\n".join([d.page_content for d in docs])

    prompt = f"""
    You are a helpful assistant. Answer *only* using the information provided in the context.
    If the answer is not in the context, say: "The answer is not in the document."

    CONTEXT:
    {context}

    QUESTION:
    {query}
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content

ask_question("main focus of the document in 2 words")

import pandas as pd

# ✏️ Put ground-truth answers here (manually or auto-generated)
ground_truths = {
    "Summarize the document?": "The document discusses the Spanish Central Credit Register (CIR), which is managed by the Banco de España and contains detailed monthly information on loans exceeding 6,000 euros to non-financial firms in Spain since 1995. It notes that due to the low reporting threshold, nearly all firms with outstanding bank debt are included in the CIR. Additionally, the document lists various statistical analyses related to loan granting and macroeconomic variables, presenting findings such as R-squared and adjusted R-squared values from different regressions categorized by loan type. It also acknowledges contributions from several individuals and institutions involved in the research.",
    "Who is the author?": "The answer is not in the document"
}

eval_questions = [
    "Summarize the document?",
    "Who is the author?"
]

eval_data = []

for q in eval_questions:
    answer = ask_question(q)  # your RAG output
    contexts = [str(doc.page_content) for doc in retriever.invoke(q)]
    ground_truth = ground_truths[q]          # required for answer_correctness
    reference = ground_truths[q]             # required for context_precision & recall

    eval_data.append({
        "question": str(q),
        "answer": str(answer),
        "contexts": contexts,
        "ground_truth": str(ground_truth),
        "reference": str(reference)
    })

df = pd.DataFrame(eval_data)
df

ask_question("name the author of the document")

from datasets import Dataset

ragas_dataset = Dataset.from_pandas(df)

from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    answer_correctness,
    context_precision,
    context_recall
)
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o-mini"
)

results = evaluate(
    ragas_dataset,
    metrics=[
        faithfulness,
    answer_relevancy,
    answer_correctness,
    context_precision,
    context_recall
    ],
    llm=llm
)

results

while True:
    query = input("Enter your query: ")
    if query.lower() == "exit":
        print("Exiting...")
        break

    print(ask_question(query))

